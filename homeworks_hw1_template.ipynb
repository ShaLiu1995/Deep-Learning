{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning, HW 1 Template\n",
    "This document gives a suggested outline for the coding assignment.  Please see the assignment pdf for a more complete description of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: Xiaoyu Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Algorithmic Implementation of a Multi-Class Logistic Regression without Tensorflow (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succintly, for this problem we have an input image that we have vectorized to have $p=784$ features, and the output space is $C=10$ dimensional.  To get the full details on logistic regression, please visit the example codes and and the lectures.  Succinctly, the multiclass logistic regression model is as follows:\n",
    "\n",
    "$$\\mathbf{\\gamma}=\\mathbf{W}\\mathbf{x}+\\mathbf{b},\\quad \\mathbf{W}\\in\\mathbb{R}^{C\\times p},\\quad \\mathbf{b}\\in\\mathbb{R}^{C}$$\n",
    "$$ p(y=j)=\\text{softmax}(\\mathbf{\\gamma})_j$$\n",
    "$$\\ell(y,\\gamma)=\\sum_{j=1}^C1_{(y=j)}\\log(\\text{softmax}(\\mathbf{\\gamma})_j)$$\n",
    "or, if $\\mathbf{r}$ is a one-hot encoding of $y$, then\n",
    "$$\\ell(r,\\gamma)=\\mathbf{r}\\cdot \\log(\\text{softmax}(\\mathbf{\\gamma}))$$\n",
    "We want to implement this model in more basic codes and learn it to build a better understanding of what's going on before moving to using deep learning toolkits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In is permissable in the context of this problem to use the MNIST dataset and minibatcher from Tensorflow, which should reduce the amount of bespoke coding that you have to do.\n",
    "\n",
    "Note that this function is depreciated, but it will work for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\sandl\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\sandl\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sandl\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sandl\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sandl\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data to make sure that its understood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image data:  (55000, 784)\n",
      "Testing image data:  (10000, 784)\n",
      "28 x 28 =  784\n",
      "\n",
      "Train image 1 is labelled one-hot as [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d2d34371d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset statistics# Datas \n",
    "print('Training image data: ', mnist.train.images.shape)\n",
    "print('Testing image data: ', mnist.test.images.shape)\n",
    "print('28 x 28 = ', 28*28)\n",
    "\n",
    "# Example image\n",
    "print('\\nTrain image 1 is labelled one-hot as {0}'.format(mnist.train.labels[0,:]))\n",
    "image = np.reshape(mnist.train.images[0,:],[28,28])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pull a new data example from MNIST by the following:\n",
    "\n",
    "Note that the digit will change each time you run this because it is randomly sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train image 1 is labelled one-hot as [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d2d34bfe80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_data=mnist.train.next_batch(1)\n",
    "# Example image\n",
    "\n",
    "print('\\nTrain image 1 is labelled one-hot as {0}'.format(current_data[1]))\n",
    "image = np.reshape(current_data[0],[28,28])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the functions that you need to define to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_gradient(current_parameters, data_minibatch):\n",
    "    # calculate the gradient on the data\n",
    "    W_grad = np.zeros((10, 784))\n",
    "    b_grad = np.zeros((10, ))\n",
    "    W = current_parameters[0]\n",
    "    b = current_parameters[1]\n",
    "    x = data_minibatch[0]\n",
    "    r = data_minibatch[1]\n",
    "    N = x.shape[0]\n",
    "    for i in range(N):\n",
    "        gamma = np.matmul(W, x[i]) + b\n",
    "        l_grad_gamma = softmax(gamma) - r[i]\n",
    "        W_grad += np.matmul(l_grad_gamma.reshape(1, -1).T, x[i].reshape(1, -1))\n",
    "        b_grad += l_grad_gamma\n",
    "    W_grad /= 1.0 * N\n",
    "    b_grad /= 1.0 * N\n",
    "    return W_grad, b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_loss(current_parameters, data_minibatch):\n",
    "    # calculate the loss\n",
    "    W = current_parameters[0]\n",
    "    b = current_parameters[1]\n",
    "    x = data_minibatch[0]\n",
    "    r = data_minibatch[1]\n",
    "    N = x.shape[0]\n",
    "    avg_loss = 0.0\n",
    "    for i in range(N):\n",
    "        gamma = np.matmul(W, x[i]) + b\n",
    "        curr_loss = np.matmul(r[i], np.log(softmax(gamma)))\n",
    "        avg_loss -= curr_loss\n",
    "    return avg_loss / (1.0 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(gamma):\n",
    "    \"\"\"Compute softmax values\"\"\"\n",
    "    numerator = np.exp(gamma)\n",
    "    denominator = sum(numerator)\n",
    "    return numerator / (1.0 * denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the stochastic gradient descent optimization loop.  Note that you need to fill in the values to make this work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 500\n",
    "data_minibatch = mnist.train.next_batch(minibatch_size)\n",
    "\n",
    "max_iterations = 200 # choose the max number of iterations\n",
    "step_size = 1  # choose your step size\n",
    "W = np.random.rand(10, 784)  # choose your starting parameters (connection weights)\n",
    "b = np.random.rand(10, )  # choose your starting parameters (biases)\n",
    "training_loss_history=[]\n",
    "for iter in range(0,max_iterations):\n",
    "    # current_data=mnist.train.next_batch(1)\n",
    "    # note you need to change this to your preferred data format.\n",
    "    current_parameters = [W, b]\n",
    "    W_grad,b_grad=lr_gradient(current_parameters,data_minibatch)    \n",
    "    training_loss_history.append(\\\n",
    "        lr_loss(current_parameters,data_minibatch))   \n",
    "    W=W-step_size*W_grad\n",
    "    b=b-step_size*b_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be a helpful diagnostic tool to visualize the learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d2d7b13f60>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate both your training loss and accuracy and your validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.05051627057765253\n",
      "valid_loss: 0.48569323947696114\n",
      "accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# Fill in code here.\n",
    "print('train_loss: {}'.format(training_loss_history[len(training_loss_history) - 1]))\n",
    "\n",
    "data_minibatch = mnist.train.next_batch(100)\n",
    "x = data_minibatch[0]\n",
    "r = data_minibatch[1]\n",
    "N = x.shape[0] \n",
    "train_loss = 0.0\n",
    "for i in range(N):\n",
    "    prediction = softmax(np.matmul(W, x[i]) + b)\n",
    "#     print(predictions)\n",
    "#     print(r[i])\n",
    "    train_loss += -1 * np.dot(np.log(prediction), r[i])\n",
    "train_loss /= (1.0 * N)\n",
    "print('valid_loss: {}'.format(train_loss))\n",
    "\n",
    "data_minibatch = mnist.test.next_batch(1000)\n",
    "x = data_minibatch[0]\n",
    "r = data_minibatch[1]\n",
    "N = x.shape[0] \n",
    "accuracy = 0\n",
    "for i in range(N):\n",
    "    prediction = softmax(np.matmul(W, x[i]) + b)\n",
    "    if np.argmax(prediction) == np.argmax(r[i]):\n",
    "        accuracy += 1\n",
    "accuracy /= (1.0 * N)\n",
    "print('accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Algorithmic Implementation of a Multi-Class Logistic Regression with Tensorflow (30 Points)\n",
    "As above, but now you are allowed to use tensorflow to perform model learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\tSet up a logistic regression network, and learn it on MNIST using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\tSet up an MLP with a single hidden layer (you can choose the number of hidden nodes) and learn it on MNIST using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\tSet up an MLP with two hidden layers (i.e. lecture 2, slide 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Performance Comparison (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\tDid your implementations and Tensorflowâ€™s implementations from problems 2 and 3 perform the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\tWhat is the validation accuracy from the multi-class logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\tWhat is the validation accuracy from the multi-class MLP with a single hidden layer?  If you change the number of nodes in the hidden layer, how susceptible is the hold out performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\tWhat is the validation accuracy from the multi-class MLP with two hidden layer?  If you change the number of nodes in the hidden layers, how susceptible is the hold out performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)\tDo you match my reported accuracies (lecture 2, slide 58)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and evidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
